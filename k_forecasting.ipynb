{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02d89f0e-a310-41d4-a581-d8ac9f1389d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import os\n",
    "import joblib\n",
    "from enum import Enum\n",
    "import kaggle_evaluation.jane_street_inference_server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7971063c-0426-4d71-a56f-5a9649e6bc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up constants\n",
    "TARGET = 'responder_6'\n",
    "FEAT_COLS = [f\"feature_{i:02d}\" for i in range(79)]\n",
    "\n",
    "# Function to load data with optional filtering\n",
    "def load_data(date_id_range=None, time_id_range=None, columns=None, return_type='pl'):\n",
    "    data_dir = './'\n",
    "    data = pl.scan_parquet(f\"{data_dir}/train.parquet\")\n",
    "    print(type(data))\n",
    "\n",
    "    if date_id_range is not None:\n",
    "        start_date, end_date = date_id_range\n",
    "        data = data.filter((pl.col(\"date_id\") >= start_date) & (pl.col(\"date_id\") <= end_date))\n",
    "\n",
    "    if time_id_range is not None:\n",
    "        start_time, end_time = time_id_range\n",
    "        data = data.filter((pl.col(\"time_id\") >= start_time) & (pl.col(\"time_id\") <= end_time))\n",
    "\n",
    "    if columns is not None:\n",
    "        data = data.select(columns)\n",
    "\n",
    "    if return_type == 'pd':\n",
    "        return data.collect().to_pandas()\n",
    "    else:\n",
    "        return data.collect()\n",
    "\n",
    "# Function to calculate R² score\n",
    "def calculate_r2(y_true, y_pred, weights):\n",
    "    numerator = np.sum(weights * (y_true - y_pred) ** 2)\n",
    "    denominator = np.sum(weights * (y_true ** 2))\n",
    "    r2_score = 1 - (numerator / denominator)\n",
    "    return r2_score\n",
    "\n",
    "# Function to evaluate the model\n",
    "def evaluate_model(model, test_data):\n",
    "    y_pred = model.predict(test_data[FEAT_COLS])\n",
    "    y_true = test_data[TARGET].to_numpy() \n",
    "    weights = test_data['weight'].to_numpy()  \n",
    "    r2_score = calculate_r2(y_true, y_pred, weights)\n",
    "    print(f\"Sample weighted zero-mean R-squared score (R2) on test data: {r2_score}\")\n",
    "\n",
    "# Class to manage a group of models\n",
    "class ModelGroup:\n",
    "    def __init__(self):\n",
    "        self.models = []\n",
    "\n",
    "    def add_model(self, model):\n",
    "        self.models.append(model)\n",
    "\n",
    "    def predict(self, test_data):\n",
    "        preds = []\n",
    "        for model in self.models:\n",
    "            if isinstance(model, lgb.Booster):\n",
    "                pred = model.predict(test_data[FEAT_COLS])\n",
    "            elif isinstance(model, xgb.Booster):\n",
    "                pred = model.predict(xgb.DMatrix(test_data[FEAT_COLS]))\n",
    "            elif hasattr(model, 'predict'):\n",
    "                pred = model.predict(test_data[FEAT_COLS])\n",
    "            else:\n",
    "                raise ValueError(\"Unsupported model type\")\n",
    "            preds.append(pred)\n",
    "\n",
    "        avg_pred = np.mean(preds, axis=0)\n",
    "        return avg_pred\n",
    "    \n",
    "    @classmethod\n",
    "    def load(cls, file_path):\n",
    "        model_group = joblib.load(file_path)\n",
    "        return model_group\n",
    "\n",
    "# Function to train XGBoost with K-Folds\n",
    "def train_xgb_kfold(total_days=1498, n_splits=5, save_models=False):\n",
    "    model_group = ModelGroup()\n",
    "    fold_size = total_days // n_splits\n",
    "    folds = [(i * fold_size, min((i + 1) * fold_size - 1, total_days - 1)) for i in range(n_splits)]\n",
    "\n",
    "    for fold_idx in range(n_splits):\n",
    "        valid_range = folds[fold_idx]\n",
    "        train_ranges = [folds[i] for i in range(n_splits) if i != fold_idx]\n",
    "\n",
    "        print(f\"Fold {fold_idx}: validation range {valid_range}, train parts: {train_ranges}\")\n",
    "\n",
    "        valid_data = load_data(date_id_range=valid_range, columns=[\"date_id\", \"weight\"] + FEAT_COLS + [TARGET], return_type='pl')\n",
    "        valid_weight = valid_data['weight'].to_pandas()\n",
    "\n",
    "        train_data = None\n",
    "        for train_range in train_ranges:\n",
    "            partial_train_data = load_data(date_id_range=train_range, columns=[\"date_id\", \"weight\"] + FEAT_COLS + [TARGET], return_type='pl')\n",
    "            if train_data is None:\n",
    "                train_data = partial_train_data\n",
    "            else:\n",
    "                train_data = train_data.vstack(partial_train_data)\n",
    "\n",
    "        train_weight = train_data['weight'].to_pandas()\n",
    "\n",
    "        dtrain = xgb.DMatrix(train_data.select(FEAT_COLS).to_pandas(), label=train_data[TARGET].to_pandas(), weight=train_weight)\n",
    "        dvalid = xgb.DMatrix(valid_data.select(FEAT_COLS).to_pandas(), label=valid_data[TARGET].to_pandas(), weight=valid_weight)\n",
    "\n",
    "        XGB_PARAMS = {\n",
    "            'eval_metric': 'rmse',\n",
    "            'learning_rate': 0.5,\n",
    "            'max_depth': 6,\n",
    "            'min_child_weight': 1,\n",
    "            'subsample': 0.8,\n",
    "            'colsample_bytree': 0.8,\n",
    "            'random_state': 42,\n",
    "            'tree_method': 'gpu_hist',\n",
    "        }\n",
    "\n",
    "        model = xgb.train(XGB_PARAMS, dtrain, num_boost_round=1000, evals=[(dtrain, 'train'), (dvalid, 'valid')], early_stopping_rounds=100, verbose_eval=50)\n",
    "\n",
    "        y_valid_pred = model.predict(dvalid)\n",
    "        r2_score = calculate_r2(valid_data[TARGET].to_pandas(), y_valid_pred, valid_weight)\n",
    "        print(f\"Fold {fold_idx} validation R2 score: {r2_score}\")\n",
    "\n",
    "        model_group.add_model(model)\n",
    "\n",
    "    if save_models:\n",
    "        joblib.dump(model_group, \"xgb_model_group.pkl\")\n",
    "        print(\"Saved the model group to xgb_model_group.pkl\")\n",
    "    \n",
    "    return model_group\n",
    "\n",
    "# Uncomment to train a new model\n",
    "# total_days = 1699\n",
    "# xgb_models = train_xgb_kfold(total_days=total_days, n_splits=5, save_models=False)\n",
    "\n",
    "# Load pre-trained model group\n",
    "xgb_models = ModelGroup.load(\"./xgb_model_group.pkl\")\n",
    "lags_ = None\n",
    "\n",
    "# Prediction function for the inference server\n",
    "def predict(test: pl.DataFrame, lags: pl.DataFrame | None) -> pl.DataFrame | pd.DataFrame:\n",
    "    global lags_\n",
    "    if lags is not None:\n",
    "        lags_ = lags\n",
    "\n",
    "    feat = test[FEAT_COLS].to_pandas()\n",
    "    pred = xgb_models.predict(feat)\n",
    "\n",
    "    predictions = test.select('row_id').with_columns(pl.Series('responder_6', pred.ravel()))\n",
    "\n",
    "    assert isinstance(predictions, (pl.DataFrame, pd.DataFrame))\n",
    "    assert list(predictions.columns) == ['row_id', 'responder_6']\n",
    "    assert len(predictions) == len(test)\n",
    "\n",
    "    return predictions\n",
    "\n",
    "# Set up the inference server\n",
    "inference_server = kaggle_evaluation.jane_street_inference_server.JSInferenceServer(predict)\n",
    "\n",
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    inference_server.serve()\n",
    "else:\n",
    "    inference_server.run_local_gateway(\n",
    "        (\n",
    "            'test.parquet',\n",
    "            'lags.parquet',\n",
    "        )\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eace53f0-d94f-4071-aecb-782740fac878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyarrow in ./venv_for/lib/python3.10/site-packages (18.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a374d014-dd25-4eab-ad8a-e475a3264279",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82d11340-8334-4bb3-9021-02b20bfb4d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from typing import Optional, Union\n",
    "\n",
    "# Set up constants\n",
    "TARGET = 'responder_6'\n",
    "FEAT_COLS = [f\"feature_{i:02d}\" for i in range(79)]\n",
    "\n",
    "# Function to load data with optional filtering\n",
    "def load_data(\n",
    "    date_id_range: Optional[tuple[int, int]] = None,\n",
    "    time_id_range: Optional[tuple[int, int]] = None,\n",
    "    columns: Optional[list[str]] = None,\n",
    "    return_type: str = 'pl'\n",
    ") -> Union[pl.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Load data from parquet file with optional filters on date_id and time_id.\n",
    "    Converts to pandas DataFrame if return_type is 'pd'.\n",
    "    \"\"\"\n",
    "    data_dir = './'\n",
    "    data = pl.scan_parquet(f\"{data_dir}/train.parquet\")\n",
    "    print(f\"Data type: {type(data)}\")\n",
    "\n",
    "    # Filter by date_id if range is specified\n",
    "    if date_id_range is not None:\n",
    "        start_date, end_date = date_id_range\n",
    "        data = data.filter((pl.col(\"date_id\") >= start_date) & (pl.col(\"date_id\") <= end_date))\n",
    "\n",
    "    # Filter by time_id if range is specified\n",
    "    if time_id_range is not None:\n",
    "        start_time, end_time = time_id_range\n",
    "        data = data.filter((pl.col(\"time_id\") >= start_time) & (pl.col(\"time_id\") <= end_time))\n",
    "\n",
    "    # Select specified columns\n",
    "    if columns is not None:\n",
    "        data = data.select(columns)\n",
    "\n",
    "    # Return data in the requested format\n",
    "    if return_type == 'pd':\n",
    "        return data.collect().to_pandas()\n",
    "    return data.collect()\n",
    "\n",
    "# Function to calculate R² score\n",
    "def calculate_r2(y_true: np.ndarray, y_pred: np.ndarray, weights: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Compute R² (coefficient of determination) with sample weights.\n",
    "    \"\"\"\n",
    "    numerator = np.sum(weights * (y_true - y_pred) ** 2)\n",
    "    denominator = np.sum(weights * (y_true ** 2))\n",
    "    return 1 - (numerator / denominator)\n",
    "\n",
    "# Function to evaluate the model\n",
    "def evaluate_model(model, test_data: pl.DataFrame) -> None:\n",
    "    \"\"\"\n",
    "    Evaluate the model's performance using R² score on test data.\n",
    "    \"\"\"\n",
    "    y_pred = model.predict(test_data[FEAT_COLS])\n",
    "    y_true = test_data[TARGET].to_numpy()\n",
    "    weights = test_data['weight'].to_numpy()\n",
    "    r2_score = calculate_r2(y_true, y_pred, weights)\n",
    "    print(f\"Sample weighted zero-mean R-squared score (R2) on test data: {r2_score}\")\n",
    "\n",
    "# Class to manage a group of models\n",
    "class ModelGroup:\n",
    "    def __init__(self) -> None:\n",
    "        self.models = []\n",
    "\n",
    "    def add_model(self, model) -> None:\n",
    "        \"\"\"Add a model to the model group.\"\"\"\n",
    "        self.models.append(model)\n",
    "\n",
    "    def predict(self, test_data: pl.DataFrame) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Make predictions by averaging outputs of all models in the group.\n",
    "        \"\"\"\n",
    "        preds = []\n",
    "        for model in self.models:\n",
    "            if isinstance(model, lgb.Booster):\n",
    "                pred = model.predict(test_data[FEAT_COLS])\n",
    "            elif isinstance(model, xgb.Booster):\n",
    "                pred = model.predict(xgb.DMatrix(test_data[FEAT_COLS]))\n",
    "            elif hasattr(model, 'predict'):\n",
    "                pred = model.predict(test_data[FEAT_COLS])\n",
    "            else:\n",
    "                raise ValueError(\"Unsupported model type\")\n",
    "            preds.append(pred)\n",
    "\n",
    "        return np.mean(preds, axis=0)\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, file_path: str) -> 'ModelGroup':\n",
    "        \"\"\"Load the model group from a saved file.\"\"\"\n",
    "        return joblib.load(file_path)\n",
    "\n",
    "# Function to train XGBoost with K-Folds\n",
    "def train_xgb_kfold(total_days: int = 1498, n_splits: int = 5, save_models: bool = False) -> ModelGroup:\n",
    "    \"\"\"\n",
    "    Train XGBoost models using K-Folds cross-validation.\n",
    "    \"\"\"\n",
    "    model_group = ModelGroup()\n",
    "    fold_size = total_days // n_splits\n",
    "    folds = [(i * fold_size, min((i + 1) * fold_size - 1, total_days - 1)) for i in range(n_splits)]\n",
    "\n",
    "    for fold_idx in range(n_splits):\n",
    "        valid_range = folds[fold_idx]\n",
    "        train_ranges = [folds[i] for i in range(n_splits) if i != fold_idx]\n",
    "\n",
    "        print(f\"Fold {fold_idx}: validation range {valid_range}, train parts: {train_ranges}\")\n",
    "\n",
    "        # Load validation data\n",
    "        valid_data = load_data(date_id_range=valid_range, columns=[\"date_id\", \"weight\"] + FEAT_COLS + [TARGET], return_type='pl')\n",
    "        valid_weight = valid_data['weight'].to_pandas()\n",
    "\n",
    "        # Load training data\n",
    "        train_data = None\n",
    "        for train_range in train_ranges:\n",
    "            partial_train_data = load_data(date_id_range=train_range, columns=[\"date_id\", \"weight\"] + FEAT_COLS + [TARGET], return_type='pl')\n",
    "            train_data = partial_train_data if train_data is None else train_data.vstack(partial_train_data)\n",
    "\n",
    "        train_weight = train_data['weight'].to_pandas()\n",
    "\n",
    "        # Prepare XGBoost DMatrix\n",
    "        dtrain = xgb.DMatrix(train_data.select(FEAT_COLS).to_pandas(), label=train_data[TARGET].to_pandas(), weight=train_weight)\n",
    "        dvalid = xgb.DMatrix(valid_data.select(FEAT_COLS).to_pandas(), label=valid_data[TARGET].to_pandas(), weight=valid_weight)\n",
    "\n",
    "        # XGBoost parameters\n",
    "        XGB_PARAMS = {\n",
    "            'eval_metric': 'rmse',\n",
    "            'learning_rate': 0.5,\n",
    "            'max_depth': 6,\n",
    "            'min_child_weight': 1,\n",
    "            'subsample': 0.8,\n",
    "            'colsample_bytree': 0.8,\n",
    "            'random_state': 42,\n",
    "            'tree_method': 'gpu_hist',\n",
    "        }\n",
    "\n",
    "        # Train model\n",
    "        model = xgb.train(XGB_PARAMS, dtrain, num_boost_round=1000, evals=[(dtrain, 'train'), (dvalid, 'valid')], early_stopping_rounds=100, verbose_eval=50)\n",
    "\n",
    "        # Evaluate model performance on validation data\n",
    "        y_valid_pred = model.predict(dvalid)\n",
    "        r2_score = calculate_r2(valid_data[TARGET].to_pandas(), y_valid_pred, valid_weight)\n",
    "        print(f\"Fold {fold_idx} validation R2 score: {r2_score}\")\n",
    "\n",
    "        # Add model to the group\n",
    "        model_group.add_model(model)\n",
    "\n",
    "    # Save models if required\n",
    "    if save_models:\n",
    "        joblib.dump(model_group, \"xgb_model_group.pkl\")\n",
    "        print(\"Saved the model group to xgb_model_group.pkl\")\n",
    "    \n",
    "    return model_group\n",
    "\n",
    "# Uncomment to train a new model\n",
    "# total_days = 1699\n",
    "# xgb_models = train_xgb_kfold(total_days=total_days, n_splits=5, save_models=False)\n",
    "\n",
    "# Load pre-trained model group\n",
    "xgb_models = ModelGroup.load(\"./xgb_model_group.pkl\")\n",
    "lags_ = None\n",
    "\n",
    "# Prediction function for the inference server\n",
    "def predict(test: pl.DataFrame, lags: Optional[pl.DataFrame] = None) -> Union[pl.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Predict using the trained models in the model group.\n",
    "    \"\"\"\n",
    "    global lags_\n",
    "    if lags is not None:\n",
    "        lags_ = lags\n",
    "\n",
    "    feat = test[FEAT_COLS].to_pandas()\n",
    "    pred = xgb_models.predict(feat)\n",
    "\n",
    "    predictions = test.select('row_id').with_columns(pl.Series('responder_6', pred.ravel()))\n",
    "\n",
    "    assert isinstance(predictions, (pl.DataFrame, pd.DataFrame))\n",
    "    assert list(predictions.columns) == ['row_id', 'responder_6']\n",
    "    assert len(predictions) == len(test)\n",
    "\n",
    "    return predictions\n",
    "\n",
    "# Set up the inference server\n",
    "inference_server = kaggle_evaluation.jane_street_inference_server.JSInferenceServer(predict)\n",
    "\n",
    "# Decide whether to run the competition server or local gateway\n",
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    inference_server.serve()\n",
    "else:\n",
    "    inference_server.run_local_gateway(('test.parquet', 'lags.parquet'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3902f096-38d4-4c41-ad1e-6d2a1e3d2e7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
